# Spring Boot Kafka

![spring-boot-kafka](../images/spring-boot-kafka.webp)

我们前面学习了Kafka的基本知识，今天，我们就让Kafka集合Spring boot，来发挥它最大的价值吧！

## Spring Boot 集成Kafka

**Step1: 引入Kafka的依赖**
创建Spring Boot项目，引入下面的依赖：
```
dependencies {
	implementation 'org.springframework.boot:spring-boot-starter-web'
	implementation 'org.springframework.kafka:spring-kafka'
	testImplementation 'org.springframework.boot:spring-boot-starter-test'
	testImplementation 'org.springframework.kafka:spring-kafka-test'
}
```

**Step2: 添加Kafka的配置**
```yml
spring:
  kafka:
    bootstrap-servers: 127.0.0.1:9092 // Kafka主机地址
```

**Step3：构建消息生产者**
我们可以通过定义REST Controller的方式来实现消息的生产者。Spring提供的Kafka的包中，给我们提供了`KafkaTemplate`的类，方便我们发送消息。
```java
@RestController
public class ProducerController {

    private static final String TOPIC = "test";

    @Autowired
    private KafkaTemplate<Object, Object> kafkaTemplate;

    @GetMapping("/send-message/{value}")
    public String sendMessage(@PathVariable String value) {
        kafkaTemplate.send(TOPIC, value);
        return "Send message: " + value +" successfully!";
    }
}
```

**Step4: 构建消费者**

Spring的Kafka给我们提供了`@KafkaListener`注解用于监听Topic的消息，可以实现消费者：
```java
@Component
public class Consumer {
    @KafkaListener(groupId = "my-groupId", topics = "test")
    public void listen(String input) {
        System.out.println("input value: " + input);
    }
}
```

**Step5: 测试**

可以在命令行中输入下面的命令：
```bash
curl --location --request GET 'http://localhost:8080/send-message/hello-world'
Send message: hello-world successfully!
```

查看应用程序的控制台已经打印出如下的数据：
```bash
input value: hello-world
```

到此，我们就已经使用Spring Boot 和 Kafka搭建了一个十分精简的消息队列处理程序！

## 详细配置说明

上面我们通过简单的例子来搭建了一套消息队列应用程序，但是这仅仅是一个Demo，距离实战应用还有很大差距，下面我们来讲解一些在生产中常见的配置和应用！

### 生产者配置

#### 1. 将消息发送到指定分区上

kafka中每个topic可定义多个分区，那么生产者将消息发送到topic时，具体追加到哪个分区呢？

如果未指定发送的分区，则会通过业务Key的hash运算，算出消息往那个分区上面发送！如果想要指定发送的分区，可以在Send方法里面指定分区，Send方法的原理是通过ProducerRecord类来发送消息，例如
```java
@GetMapping("/send-message/{value}")
public String sendMessage(@PathVariable String value) {
    kafkaTemplate.send(TOPIC, 0, "key", value);
    return "Send message: " + value +" successfully!";
}

// send方法原理
@Override
public CompletableFuture<SendResult<K, V>> send(String topic, Integer partition, K key, @Nullable V data) {
    ProducerRecord<K, V> producerRecord = new ProducerRecord<>(topic, partition, key, data);
    return observeSend(producerRecord);
}
```

#### 2. 生产者同步或发送消息

生产者可以使用同步的方式来发送消息，在收到Kafka的回复之前，线程将进入阻塞状态。Kafka给生产者的回复被称之为ACK，生产者会给Kafka 3S的时间等待，如果超过3S还没收到ACK，就会进行重试，重试的次数为3次。

对于ACK来说，会有三个配置：
* 0：表示生产者Producer不需要等待任务Broker确认收到消息的回复，就可以继续发送下一条消息，性能最高，但是最容易丢数据。
* 1：表示生产者需要等待Leader已经成功将数据写入本地Log，但是不需要等待所有的follower是否写入成功，就可以继续发送下一条消息。这种情况下，如果follower没有成功备份数据，而此时Leader又挂掉，则消息会丢失。此方案的优势是性能和安全性是最均衡的。
* -1或all：表示生产者需要等待`min.insync.replicas(默认为1，推荐配置大于等于2)`这个参数的配置的副本个数都成功写入日志，这种策略就表示只要有一个备份存活就不会丢失数据，是最强的数据保证，性能最低。

配置代码如下：
```yml
spring:
  kafka:
    bootstrap-servers: 127.0.0.1:9092
    producer:
      acks: 1
```

同步发送代码如下：
```java
@GetMapping("/send-message/{value}")
public String sendMessage(@PathVariable String value) throws ExecutionException, InterruptedException {
    SendResult<Object, Object> result = kafkaTemplate.send(TOPIC, value).get();
    RecordMetadata recordMetadata = result.getRecordMetadata();
    return "Send message: " + value +" to topic: " + recordMetadata.topic() +
            "; partition is " + recordMetadata.partition() + "; offset is " + recordMetadata.offset();
}
```

当然，也可以通过异步的方式来发送消息，不需要等待消息队列的返回，就可以执行后面的业务逻辑，只要消息返回之后，通过回调函数来实现。
```java
@GetMapping("/send-message/{value}")
public String sendMessage(@PathVariable String value) throws ExecutionException, InterruptedException {
    CompletableFuture<SendResult<Object, Object>> sendFuture = kafkaTemplate.send(TOPIC, value);
    sendFuture.thenAcceptAsync(result -> {
        RecordMetadata recordMetadata = result.getRecordMetadata();
        System.out.println("Send message: " + value +" to topic: " + recordMetadata.topic() +
                "; partition is " + recordMetadata.partition() + "; offset is " + recordMetadata.offset());
    });
    System.out.println("Send message: " + value);
    return "Send message: " + value;
}
```

#### 3.生产者消息发送的缓冲区

Spring Kafka会默认创建一个消息缓冲区，用来存放要发送的消息，缓存区默认为32M。本地线程默认会去缓冲区中一次拉取16K的数据，发送到Broker，如果线程拉不到16K的数据，间隔10ms也会将已拉取到的数据发送到Broker。

此配置可以在配置文件中修改：
```yml
spring:
  kafka:
    bootstrap-servers: 127.0.0.1:9092
    producer:
      acks: 1
      batch-size: 16384
      buffer-memory: 33554432
```